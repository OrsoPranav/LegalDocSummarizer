{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cf3e374",
   "metadata": {
    "id": "6cf3e374"
   },
   "source": [
    "### Script to generate summaries using Legal-LED model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ad1e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"IN-Abs\" # Options: IN - IN-Abs, UK-UK-Abs, N2-IN-Ext\n",
    "output_path = \"./output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97d9c740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "!pip install nltk datasets evaluate\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2895caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from utilities import *\n",
    "import os\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d7a6d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af7086d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7030\n",
      "7030\n",
      "7030\n",
      "['']\n"
     ]
    }
   ],
   "source": [
    "#Reading the test documents\n",
    "names, data_source, data_summary = get_summary_data(dataset, \"test\")\n",
    "print(len(names))\n",
    "print(len(data_source))\n",
    "print(len(data_summary))\n",
    "len_dic = dict_names = get_req_len_dict(dataset, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07a2744e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/pranav/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import torch\n",
    "import datasets\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import LEDTokenizer, LEDForConditionalGeneration\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f97b9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"nsi319/legal-led-base-16384\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7721acec",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_max_length = 1024*16\n",
    "decoder_max_length = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2667bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "led = AutoModelForSeq2SeqLM.from_pretrained(model_name, gradient_checkpointing=True, use_cache=False)\n",
    "# set generate hyperparameters\n",
    "led.config.num_beams = 2\n",
    "led.config.max_length = decoder_max_length\n",
    "led.config.min_length = 256\n",
    "led.config.early_stopping = True\n",
    "led.config.no_repeat_ngram_size = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebe2023",
   "metadata": {},
   "outputs": [],
   "source": [
    "led = AutoModelForSeq2SeqLM.from_pretrained(\"/kaggle/input/led-model/LED/IN_model\", use_cache=False)\n",
    "led = led.to(\"gpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd35ada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "led.eval()\n",
    "\n",
    "def generate_summary_gpu(input_text, l):\n",
    "\tinputs = tokenizer(\n",
    "\t\tinput_text,\n",
    "\t\tpadding=\"max_length\",\n",
    "\t\ttruncation=True,\n",
    "\t\tmax_length=encoder_max_length,\n",
    "\t\treturn_tensors=\"pt\",\n",
    "\t)\n",
    "\tinput_ids = inputs.input_ids.to(led.device)\n",
    "\tattention_mask = inputs.attention_mask.to(led.device)\n",
    "\tglobal_attention_mask = torch.zeros_like(attention_mask)\n",
    "\t# put global attention on <s> token\n",
    "\tglobal_attention_mask[:, 0] = 1\n",
    "\tl = max(l,256)\n",
    "\tl = min(l,1024)\n",
    "\toutputs = led.generate(input_ids, attention_mask=attention_mask, global_attention_mask=global_attention_mask, max_length = l, num_beams = 2,repetition_penalty = 2.5,early_stopping = True)\t\n",
    "\tpreds = [tokenizer.decode(gen_id, skip_special_tokens=True, clean_up_tokenization_space=True) for gen_id in outputs]\n",
    "\treturn \"\".join(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e1530e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 1577.txt - 3532 : 403\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    name = names[i]\n",
    "    doc = data_source[i]\n",
    "    wc = doc.split(\" \")\n",
    "    input_len = len(wc)\n",
    "    req_len = dict_names[name]\n",
    "    print(str(i) + \": \" + name +  \" - \" + str(input_len) + \" : \" + str(req_len))\n",
    "    \n",
    "    abs_summ = generate_summary_gpu(doc,req_len)\n",
    "    if len(abs_summ.split(\" \")) > req_len:\n",
    "        abs_summ = abs_summ.split(\" \")\n",
    "        abs_summ = abs_summ[:req_len]\n",
    "        abs_summ = \" \".join(abs_summ)\n",
    "    print(abs_summ)\n",
    "    print(len((abs_summ.split(\" \"))))\n",
    "    path = output_path + name\n",
    "    file = open(path,'w')\n",
    "    file.write(abs_summ)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e759f0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ed58da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "pegasus_finetune.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
